<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Detection Model Interface</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f7f7f7;
        }
    </style>
</head>
<body class="bg-gray-100 min-h-screen flex items-center justify-center p-4">

    <div class="w-full max-w-2xl bg-white shadow-xl rounded-2xl p-8 space-y-8">
        <header class="text-center">
            <h1 class="text-3xl font-bold text-gray-800">Facial Emotion Detector (ML Project)</h1>
            <p class="text-lg text-gray-500 mt-2">Final Project for {{ '{{ model_status }}' }}</p>
        </header>

        <!-- Main Content Area: Webcam Feed and Prediction Output -->
        <main class="space-y-6">
            <div class="flex flex-col md:flex-row gap-6">
                <!-- Webcam/Video Placeholder -->
                <div class="flex-1 bg-gray-200 rounded-xl shadow-inner p-4 flex items-center justify-center h-64 md:h-80">
                    <p class="text-gray-600 text-center font-semibold">
                        [Webcam Feed Placeholder]
                        <br>
                        (JavaScript/OpenCV.js implementation goes here)
                    </p>
                </div>

                <!-- Live Prediction Output -->
                <div class="md:w-1/3 bg-blue-500 text-white rounded-xl shadow-lg p-6 flex flex-col justify-center items-center text-center">
                    <h2 class="text-xl font-semibold mb-3">Live Emotion</h2>
                    <p id="emotion-output" class="text-5xl font-extrabold tracking-tight">Neutral</p>
                    <p id="confidence-output" class="text-sm opacity-80 mt-2">Confidence: 0.00</p>
                </div>
            </div>

            <!-- Control Panel -->
            <div class="bg-gray-50 p-4 rounded-xl shadow-md border border-gray-200">
                <h3 class="text-xl font-semibold text-gray-700 mb-3">Controls</h3>
                <button id="start-btn" class="w-full px-4 py-2 bg-green-600 text-white font-medium rounded-lg hover:bg-green-700 transition duration-150 shadow-md">
                    Start Detection
                </button>
                <p class="text-sm text-gray-500 mt-2 text-center">
                    Click Start to activate the webcam and begin real-time emotion analysis.
                </p>
            </div>
        </main>

        <footer class="pt-4 border-t text-center text-sm text-gray-400">
            <p>&copy; 2024 Emotion Detection System</p>
        </footer>
    </div>

    <script>
        // Simple client-side script to handle the start button interaction
        document.getElementById('start-btn').addEventListener('click', () => {
            document.getElementById('emotion-output').textContent = 'Loading...';
            document.getElementById('confidence-output').textContent = 'Awaiting feed...';

            // In a real application, this would start the webcam, capture frames,
            // and send the image data to the /predict_emotion endpoint via a fetch API call.
            
            console.log("Starting webcam stream and API interaction (Placeholder).");
            
            // Simulating an API call for demonstration:
            setTimeout(() => {
                const dummyEmotion = ["Happy", "Sad", "Neutral"][Math.floor(Math.random() * 3)];
                const dummyConfidence = (Math.random() * 0.9 + 0.1).toFixed(2); // 0.1 to 1.0

                document.getElementById('emotion-output').textContent = dummyEmotion;
                document.getElementById('confidence-output').textContent = `Confidence: ${dummyConfidence}`;
            }, 2000);
        });
    </script>

</body>
</html>
